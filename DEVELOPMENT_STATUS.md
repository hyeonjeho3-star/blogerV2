# Blog Mate v2.0 - ê°œë°œ í˜„í™© ë³´ê³ ì„œ

> ìµœì¢… ì—…ë°ì´íŠ¸: 2025-11-19
> í˜„ì¬ ìƒíƒœ: **Phase 3 ì™„ë£Œ** âœ…

---

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
3. [Phase 1: Project Bootstrap](#phase-1-project-bootstrap)
4. [Phase 2: Keyword Generation Engine](#phase-2-keyword-generation-engine)
5. [Phase 3: Smart Discovery Service](#phase-3-smart-discovery-service)
6. [í…ŒìŠ¤íŠ¸ í˜„í™©](#í…ŒìŠ¤íŠ¸-í˜„í™©)
7. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
8. [ë‹¤ìŒ ë‹¨ê³„](#ë‹¤ìŒ-ë‹¨ê³„)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

**Blog Mate v2.0**ì€ AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ í‚¤ì›Œë“œ ë°œêµ´ ë° ë¸”ë¡œê·¸ ì»¨í…ì¸  ìƒì„± í”Œë«í¼ì…ë‹ˆë‹¤.

### í•µì‹¬ ê¸°ëŠ¥
- ğŸ” **Smart Discovery**: í‚¤ì›Œë“œ ìë™ ë°œêµ´ ë° ê¸°íšŒ ì ìˆ˜ ë¶„ì„
- ğŸ“Š **Trend Analysis**: ë„¤ì´ë²„ DataLab ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„
- ğŸ¤– **AI Content Generation**: Google Gemini ê¸°ë°˜ ì»¨í…ì¸  ìë™ ìƒì„± (Phase 4 ì˜ˆì •)
- ğŸ“ˆ **Performance Dashboard**: ì‹¤ì‹œê°„ ë¶„ì„ ë° ë¦¬í¬íŒ… (Phase 5 ì˜ˆì •)

### ê°œë°œ ë¡œë“œë§µ
```
âœ… Phase 1: Project Bootstrap (ì™„ë£Œ)
âœ… Phase 2: Keyword Generation Engine (ì™„ë£Œ)
âœ… Phase 3: Smart Discovery Service (ì™„ë£Œ)
â³ Phase 4: AI Content Generation Engine (ì˜ˆì •)
â³ Phase 5: Performance & Dashboard (ì˜ˆì •)
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
blog-mate2/
â”œâ”€â”€ app/                          # Streamlit UI
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ 1_ğŸ”_smart_discovery.py   # Smart Discovery UI (Phase 3)
â”‚   â”‚   â”œâ”€â”€ 2_ğŸ“_content_gen.py       # Content Generation (Phase 4 ì˜ˆì •)
â”‚   â”‚   â””â”€â”€ 3_ğŸ“Š_comparison.py        # Comparison (Phase 2 ê¸°ë°˜)
â”‚   â””â”€â”€ main.py                   # ë©”ì¸ ì•±
â”‚
â”œâ”€â”€ backend/                      # ë°±ì—”ë“œ ë¡œì§
â”‚   â”œâ”€â”€ models/                   # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ keyword_trend.py          # í‚¤ì›Œë“œ íŠ¸ë Œë“œ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ keyword_batch.py          # ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ analysis_result.py        # ë¶„ì„ ê²°ê³¼ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ opportunity_score.py      # ê¸°íšŒ ì ìˆ˜ ëª¨ë¸ (Phase 3)
â”‚   â”‚   â””â”€â”€ discovery_result.py       # ë°œêµ´ ê²°ê³¼ ëª¨ë¸ (Phase 3)
â”‚   â”‚
â”‚   â”œâ”€â”€ analyzers/                # ë¶„ì„ê¸°
â”‚   â”‚   â”œâ”€â”€ base_analyzer.py          # ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤
â”‚   â”‚   â””â”€â”€ datalab_analyzer.py       # ë„¤ì´ë²„ DataLab ë¶„ì„ê¸° v2.0
â”‚   â”‚
â”‚   â”œâ”€â”€ generators/               # í‚¤ì›Œë“œ ìƒì„±ê¸°
â”‚   â”‚   â”œâ”€â”€ base_generator.py         # ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ keyword_generator.py      # ë¡±í…Œì¼ í‚¤ì›Œë“œ ìƒì„±ê¸°
â”‚   â”‚   â””â”€â”€ autocomplete_generator.py # ë„¤ì´ë²„ ìë™ì™„ì„± í¬ë¡¤ëŸ¬
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                 # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ keyword_comparison_service.py  # í‚¤ì›Œë“œ ë¹„êµ ì„œë¹„ìŠ¤
â”‚   â”‚   â”œâ”€â”€ batch_processor.py             # ë°°ì¹˜ ë¶„ì„ í”„ë¡œì„¸ì„œ
â”‚   â”‚   â”œâ”€â”€ opportunity_scorer.py          # ê¸°íšŒ ì ìˆ˜ ê³„ì‚° (Phase 3)
â”‚   â”‚   â””â”€â”€ smart_discovery_service.py     # ìŠ¤ë§ˆíŠ¸ ë°œêµ´ ì„œë¹„ìŠ¤ (Phase 3)
â”‚   â”‚
â”‚   â””â”€â”€ utils/                    # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ logger.py                 # ë¡œê¹… (loguru í´ë°±)
â”‚       â”œâ”€â”€ api_client.py             # HTTP í´ë¼ì´ì–¸íŠ¸ (httpx í´ë°±)
â”‚       â”œâ”€â”€ file_handler.py           # íŒŒì¼ I/O
â”‚       â”œâ”€â”€ cache_manager.py          # ìºì‹œ ê´€ë¦¬ ì‹œìŠ¤í…œ (Phase 3)
â”‚       â””â”€â”€ progress_tracker.py       # ì§„í–‰ë¥  ì¶”ì  (Phase 3)
â”‚
â”œâ”€â”€ config/                       # ì„¤ì •
â”‚   â””â”€â”€ settings.py               # Pydantic Settings (í´ë°± í¬í•¨)
â”‚
â”œâ”€â”€ tests/                        # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ unit/                     # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (80ê°œ)
â”‚   â”‚   â”œâ”€â”€ test_models.py
â”‚   â”‚   â”œâ”€â”€ test_analyzers.py
â”‚   â”‚   â”œâ”€â”€ test_generators.py
â”‚   â”‚   â”œâ”€â”€ test_opportunity_scorer.py     (16 tests)
â”‚   â”‚   â”œâ”€â”€ test_cache_manager.py          (17 tests)
â”‚   â”‚   â”œâ”€â”€ test_smart_discovery_service.py (20 tests)
â”‚   â”‚   â””â”€â”€ test_progress_tracker.py       (27 tests)
â”‚   â””â”€â”€ integration/              # í†µí•© í…ŒìŠ¤íŠ¸ (Phase 3.6 ì˜ˆì •)
â”‚
â”œâ”€â”€ .env.example                  # í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿
â”œâ”€â”€ requirements.txt              # ì˜ì¡´ì„± (Python 3.14 í˜¸í™˜)
â””â”€â”€ pytest.ini                    # Pytest ì„¤ì •
```

---

## âœ… Phase 1: Project Bootstrap

**ëª©í‘œ**: í”„ë¡œì íŠ¸ ê¸°ë³¸ êµ¬ì¡° ë° ì¸í”„ë¼ êµ¬ì¶•

### êµ¬í˜„ ë‚´ìš©

#### 1.1 ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
- ì „ì²´ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
- `__init__.py` íŒŒì¼ ìë™ ìƒì„±
- `.gitkeep` íŒŒì¼ë¡œ ë¹ˆ ë””ë ‰í† ë¦¬ ìœ ì§€

#### 1.2 ì˜ì¡´ì„± ê´€ë¦¬
```python
# requirements.txt (ì£¼ìš” íŒ¨í‚¤ì§€)
streamlit>=1.28.0
pydantic>=2.0.0
httpx>=0.24.0
pandas>=2.0.0
numpy>=1.24.0
openpyxl>=3.1.0
pytest>=7.4.0
loguru>=0.7.0
```

**Python 3.14 í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°**:
- ì‚¬ì „ ë¹Œë“œëœ wheel ìš°ì„  ì„¤ì¹˜
- ë²„ì „ ì œì•½ ì™„í™” (>= ë°©ì‹ ì‚¬ìš©)
- ëˆ„ë½ëœ íŒ¨í‚¤ì§€ í´ë°± ì²˜ë¦¬

#### 1.3 í•µì‹¬ ìœ í‹¸ë¦¬í‹°
```python
# backend/utils/logger.py
- loguru ê¸°ë°˜ ë¡œê¹… (í´ë°±: í‘œì¤€ logging)
- ëª¨ë“ˆë³„ ë¡œê±° ìƒì„±: get_logger(__name__)

# backend/utils/api_client.py
- httpx ê¸°ë°˜ HTTP í´ë¼ì´ì–¸íŠ¸ (í´ë°±: ë”ë¯¸ êµ¬í˜„)
- POST/GET ë©”ì„œë“œ ì§€ì›

# backend/utils/file_handler.py
- JSON/Text íŒŒì¼ I/O
- íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ëª… ìƒì„±
```

#### 1.4 ì„¤ì • ê´€ë¦¬
```python
# config/settings.py
- Pydantic Settings ê¸°ë°˜ (í´ë°± í¬í•¨)
- í™˜ê²½ ë³€ìˆ˜ ìë™ ë¡œë“œ (.env)
- API í‚¤ ê´€ë¦¬
- ê²½ë¡œ ì„¤ì • (base_dir, cache_dir, log_dir)
```

#### 1.5 Git ì„¤ì •
```bash
# .gitignore
- Python ë°”ì´íŠ¸ì½”ë“œ, ìºì‹œ
- í™˜ê²½ ë³€ìˆ˜ (.env)
- IDE ì„¤ì • (.vscode, .idea)
- ë°ì´í„° ë””ë ‰í† ë¦¬
```

### í…ŒìŠ¤íŠ¸ ê²°ê³¼
- 8/8 ê¸°ë³¸ ê²€ì¦ í…ŒìŠ¤íŠ¸ í†µê³¼ âœ…
- GitHub ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ âœ…

---

## âœ… Phase 2: Keyword Generation Engine

**ëª©í‘œ**: í‚¤ì›Œë“œ ìë™ ìƒì„± ë° íŠ¸ë Œë“œ ë¶„ì„ ì—”ì§„ êµ¬ì¶•

### êµ¬í˜„ ë‚´ìš©

#### 2.1 ë°ì´í„° ëª¨ë¸

**KeywordTrend** (`backend/models/keyword_trend.py`)
```python
class KeywordTrend(BaseModel):
    keyword: str
    average_ratio: float      # ì „ì²´ í‰ê·  ê²€ìƒ‰ ë¹„ìœ¨
    recent_ratio: float       # ìµœê·¼ 7ì¼ í‰ê· 
    momentum: float           # ì„±ì¥ ëª¨ë©˜í…€ (%)
    trend_direction: Literal['rising', 'stable', 'falling']
    velocity: float           # ë³€í™” ì†ë„
    total_score: float        # ì¢…í•© ì ìˆ˜
    trend_data: List[TrendDataPoint]
```

**KeywordBatch** (`backend/models/keyword_batch.py`)
```python
class KeywordBatch(BaseModel):
    keywords: List[str]       # ìµœëŒ€ 5ê°œ (ë„¤ì´ë²„ API ì œí•œ)
    batch_number: int
    total_batches: int
```

**AnalysisResult** (`backend/models/analysis_result.py`)
```python
class AnalysisResult(BaseModel):
    input_keywords: List[str]
    trends: List[KeywordTrend]
    best_keyword: Optional[KeywordTrend]
    total_analyzed: int
    successful: int
    failed: int
    started_at: datetime
    completed_at: datetime

    @property
    def success_rate(self) -> float
    @property
    def processing_time(self) -> float
```

#### 2.2 DataLab Analyzer v2.0

**`backend/analyzers/datalab_analyzer.py`**

í•µì‹¬ ê°œì„ ì‚¬í•­:
- **ëª¨ë©˜í…€ ê³„ì‚°**: `((ìµœê·¼7ì¼ - ì´ì „7ì¼) / ì´ì „7ì¼) * 100`
- **íŠ¸ë Œë“œ ë°©í–¥ íŒì •**:
  - Rising: momentum > 10%
  - Falling: momentum < -10%
  - Stable: -10% â‰¤ momentum â‰¤ 10%
- **ì†ë„(Velocity) ê³„ì‚°**: ì¼ë³„ ë³€í™”ìœ¨ í‰ê· 
- **í•˜ë½ íŒ¨ë„í‹°**: falling ì¶”ì„¸ ì‹œ ì ìˆ˜ Ã— 0.7

```python
def _calculate_momentum(self, trend_data: List[TrendDataPoint]) -> float:
    recent_7 = trend_data[-7:]
    previous_7 = trend_data[-14:-7]

    recent_avg = sum(p.ratio for p in recent_7) / 7
    previous_avg = sum(p.ratio for p in previous_7) / 7

    return ((recent_avg - previous_avg) / previous_avg) * 100
```

#### 2.3 í‚¤ì›Œë“œ ìƒì„±ê¸°

**LongTailGenerator** (`backend/generators/keyword_generator.py`)

10ê°œ ì¹´í…Œê³ ë¦¬, 70+ ìˆ˜ì‹ì–´:
```python
MODIFIERS = {
    'how_to': ['ë°©ë²•', 'í•˜ëŠ”ë²•', 'íŒ', 'ê°€ì´ë“œ', 'ë…¸í•˜ìš°'],
    'review': ['í›„ê¸°', 'ë¦¬ë·°', 'ì‚¬ìš©ë²•', 'ì¥ë‹¨ì '],
    'comparison': ['VS', 'ë¹„êµ', 'ì°¨ì´', 'ì¶”ì²œ', 'ìˆœìœ„'],
    'problem': ['í•´ê²°', 'ì˜¤ë¥˜', 'ë¬¸ì œ', 'ìˆ˜ë¦¬'],
    'timing': ['ì‹œê¸°', 'íƒ€ì´ë°', 'ì–¸ì œ', 'ì‹œì¦Œ'],
    'price': ['ê°€ê²©', 'ì €ë ´í•œ', 'í• ì¸', 'ê°€ì„±ë¹„'],
    'quality': ['ì¢‹ì€', 'ì¸ê¸°', 'ìœ ëª…í•œ', 'ì¶”ì²œ'],
    'location': ['ì¶”ì²œ', 'ë² ìŠ¤íŠ¸', 'ê·¼ì²˜', 'ì£¼ë³€'],
    'diy': ['DIY', 'ì§ì ‘', 'ì…€í”„', 'ë§Œë“¤ê¸°'],
    'beginner': ['ì´ˆë³´', 'ì…ë¬¸', 'ì²˜ìŒ', 'ê¸°ì´ˆ']
}
```

ìµœëŒ€ 30ê°œ ë³€í˜• ìƒì„±

**AutocompleteGenerator** (`backend/generators/autocomplete_generator.py`)

ë„¤ì´ë²„ ìë™ì™„ì„± API í™œìš©:
```python
API_URL = "https://ac.search.naver.com/nx/ac"

def generate(seed_keyword: str) -> List[str]:
    # ë„¤ì´ë²„ ê²€ìƒ‰ì°½ ìë™ì™„ì„± ê²°ê³¼ í¬ë¡¤ë§
    # httpx ë¯¸ì„¤ì¹˜ ì‹œ ë”ë¯¸ ê²°ê³¼ ë°˜í™˜
```

#### 2.4 ë°°ì¹˜ í”„ë¡œì„¸ì„œ

**BatchProcessor** (`backend/services/batch_processor.py`)

ë„¤ì´ë²„ API ì œí•œ(5ê°œ) ëŒ€ì‘:
```python
class BatchProcessor:
    def __init__(
        self,
        analyzer: DataLabAnalyzer,
        batch_size: int = 5,           # ë„¤ì´ë²„ ì œí•œ
        delay_seconds: float = 1.0,    # Rate limiting
        progress_callback: Optional[Callable] = None
    )

    def process(keywords: List[str]) -> List[KeywordTrend]:
        # í‚¤ì›Œë“œë¥¼ 5ê°œì”© ë¶„í• 
        # ë°°ì¹˜ ê°„ 1ì´ˆ ëŒ€ê¸°
        # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ
```

#### 2.5 í‚¤ì›Œë“œ ë¹„êµ ì„œë¹„ìŠ¤

**KeywordComparisonService** (`backend/services/keyword_comparison_service.py`)

```python
def compare(keywords: List[str]) -> AnalysisResult:
    # 1-5ê°œ í‚¤ì›Œë“œ ë¹„êµ
    # ìµœê³  í‚¤ì›Œë“œ ìë™ ì„ ì •
    # ìˆœìœ„ë³„ ì •ë ¬

def get_ranking(result: AnalysisResult) -> List[tuple]:
    # [(ìˆœìœ„, KeywordTrend), ...] ë°˜í™˜

def get_comparison_summary(result: AnalysisResult) -> str:
    # í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±
```

### í…ŒìŠ¤íŠ¸ ê²°ê³¼
- Phase 2 ê´€ë ¨ í…ŒìŠ¤íŠ¸ ì „ì²´ í†µê³¼ âœ…
- GitHub í‘¸ì‹œ ì™„ë£Œ âœ…

---

## âœ… Phase 3: Smart Discovery Service

**ëª©í‘œ**: í‚¤ì›Œë“œ ìë™ ë°œêµ´ ë° ê¸°íšŒ ì ìˆ˜ ë¶„ì„ ì‹œìŠ¤í…œ êµ¬ì¶•

### êµ¬í˜„ ë‚´ìš©

#### 3.1 OpportunityScore ì‹œìŠ¤í…œ

**OpportunityScore Model** (`backend/models/opportunity_score.py`)

```python
class OpportunityScore(BaseModel):
    keyword: str

    # ê°œë³„ ì ìˆ˜ (0-100)
    search_demand: float      # ê²€ìƒ‰ ìˆ˜ìš” (30%)
    momentum: float           # ì„±ì¥ ì¶”ì„¸ (35%)
    competition_gap: float    # ê²½ìŸ ê³µë°± (20%)
    suitability: float        # ë¸”ë¡œê·¸ ì í•©ë„ (15%)

    @computed_field
    @property
    def total_score(self) -> float:
        return (
            self.search_demand * 0.30 +
            self.momentum * 0.35 +
            self.competition_gap * 0.20 +
            self.suitability * 0.15
        )

    @computed_field
    @property
    def grade(self) -> Literal['S', 'A', 'B', 'C', 'D']:
        score = self.total_score
        if score >= 80: return 'S'
        elif score >= 65: return 'A'
        elif score >= 50: return 'B'
        elif score >= 35: return 'C'
        else: return 'D'
```

**OpportunityScorer** (`backend/services/opportunity_scorer.py`)

ì ìˆ˜ ê³„ì‚° ë¡œì§:
```python
def _calculate_search_demand(trend: KeywordTrend) -> float:
    # average_ratioë¥¼ 0-100 ìŠ¤ì¼€ì¼ë¡œ
    return min(100.0, max(0.0, trend.average_ratio))

def _calculate_momentum_score(trend: KeywordTrend) -> float:
    # momentum (-100~+100)ì„ 0-100ìœ¼ë¡œ ì •ê·œí™”
    # 0% â†’ 50ì , +50% â†’ 75ì , +100% â†’ 100ì 
    # -50% â†’ 25ì , -100% â†’ 0ì 

def _calculate_competition_gap(trend: KeywordTrend) -> float:
    # recent_ratioì˜ 80%ë¥¼ ê²½ìŸ ê³µë°±ìœ¼ë¡œ ê°„ì£¼
    return min(100.0, trend.recent_ratio * 0.8)

def _calculate_suitability(trend: KeywordTrend) -> float:
    score = 50.0  # ê¸°ë³¸ ì ìˆ˜
    # ê¸¸ì´ ì ìˆ˜ (5-15ì: +20ì )
    # ê³µë°± í¬í•¨ (ë¡±í…Œì¼): +15ì 
    # ë¸”ë¡œê·¸ ì¹œí™” ìˆ˜ì‹ì–´: +15ì 
    return min(100.0, score)
```

**í…ŒìŠ¤íŠ¸**: 16 tests passed âœ…

#### 3.2 CacheManager

**`backend/utils/cache_manager.py`**

íŒŒì¼ ê¸°ë°˜ JSON ìºì‹±:
```python
class CacheManager:
    def __init__(
        self,
        cache_dir: str = ".cache",
        ttl_hours: int = 24,           # 24ì‹œê°„ TTL
        index_file: str = "cache_index.json"
    )

    def save_result(
        seed_keyword: str,
        result_data: Dict,
        metadata: Optional[Dict] = None
    ) -> str:
        # JSON íŒŒì¼ë¡œ ì €ì¥
        # ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ëª…

    def load_result(seed_keyword: str) -> Optional[Dict]:
        # ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰
        # ë§Œë£Œ í™•ì¸
        # ë°ì´í„° ë¡œë“œ

    def clear_expired() -> int:
        # ë§Œë£Œëœ ìºì‹œ ìë™ ì‚­ì œ
```

ìºì‹œ êµ¬ì¡°:
```json
{
  "seed_keyword": "ë¡±íŒ¨ë”©",
  "cached_at": "2025-11-19T10:00:00",
  "expires_at": "2025-11-20T10:00:00",
  "metadata": {
    "processing_time": 5.2,
    "success_rate": 100.0
  },
  "result": { ... }
}
```

**í…ŒìŠ¤íŠ¸**: 17 tests passed âœ…

#### 3.3 SmartDiscoveryService

**DiscoveryResult Model** (`backend/models/discovery_result.py`)

```python
class DiscoveryResult(BaseModel):
    seed_keyword: str
    generated_count: int          # ìƒì„±ëœ í‚¤ì›Œë“œ ìˆ˜
    analyzed_count: int           # ë¶„ì„ëœ í‚¤ì›Œë“œ ìˆ˜
    opportunities: List[OpportunityScore]
    cache_hit: bool              # ìºì‹œ íˆíŠ¸ ì—¬ë¶€

    @computed_field
    @property
    def grade_distribution(self) -> Dict[str, int]:
        # {'S': 3, 'A': 5, 'B': 10, 'C': 7, 'D': 5}

    @computed_field
    @property
    def best_opportunity(self) -> OpportunityScore:
        # ìµœê³  ì ìˆ˜ í‚¤ì›Œë“œ
```

**SmartDiscoveryService** (`backend/services/smart_discovery_service.py`)

5ë‹¨ê³„ íŒŒì´í”„ë¼ì¸:
```python
def discover(
    seed_keyword: str,
    use_autocomplete: bool = True,
    min_grade: str = 'C',
    progress_callback: Optional[Callable] = None
) -> DiscoveryResult:

    # Stage 1: ìºì‹œ í™•ì¸
    if use_cache and cached := self._check_cache(seed_keyword):
        return cached

    # Stage 2: í‚¤ì›Œë“œ ìƒì„± (ë¡±í…Œì¼ + ìë™ì™„ì„±)
    keywords = self._generate_keywords(seed_keyword, use_autocomplete)

    # Stage 3: ë°°ì¹˜ ë¶„ì„ (ë„¤ì´ë²„ DataLab)
    trends = self._analyze_keywords(keywords)

    # Stage 4: ê¸°íšŒ ì ìˆ˜ ê³„ì‚°
    opportunities = self._calculate_scores(trends)

    # Stage 5: ë“±ê¸‰ í•„í„°ë§
    filtered = self.scorer.filter_by_grade(opportunities, min_grade)

    # ê²°ê³¼ ìƒì„± ë° ìºì‹œ ì €ì¥
    result = DiscoveryResult(...)
    self._save_to_cache(seed_keyword, result)

    return result
```

**í…ŒìŠ¤íŠ¸**: 20 tests passed âœ…

#### 3.4 ProgressTracker

**`backend/utils/progress_tracker.py`**

ë‹¨ì¼ ì‘ì—… ì¶”ì :
```python
class ProgressTracker:
    def update(current: int, message: str):
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        # ì½œë°± ì‹¤í–‰
        # Streamlit ìœ„ì ¯ ì—…ë°ì´íŠ¸

    def complete(message: str):
        # ì™„ë£Œ ì²˜ë¦¬

    # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§€ì›
    with ProgressTracker(total_steps=100) as tracker:
        tracker.update(50, "ì§„í–‰ ì¤‘")
```

ë‹¤ë‹¨ê³„ ì‘ì—… ì¶”ì :
```python
class MultiStageProgressTracker:
    def __init__(stages: List[str]):
        # 5ë‹¨ê³„: ["ìºì‹œ í™•ì¸", "í‚¤ì›Œë“œ ìƒì„±", ...]

    @property
    def overall_progress(self) -> float:
        # ì „ì²´ ì§„í–‰ë¥  (ê°€ì¤‘ì¹˜ ë°˜ì˜)

    def next_stage(message: str):
        # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
```

Streamlit í†µí•©:
```python
progress_widget = st.empty()
tracker = ProgressTracker(
    total_steps=100,
    streamlit_widget=progress_widget
)
# ìë™ìœ¼ë¡œ st.progress() ì—…ë°ì´íŠ¸
```

**í…ŒìŠ¤íŠ¸**: 27 tests passed âœ…

#### 3.5 Smart Discovery UI

**`app/pages/1_ğŸ”_smart_discovery.py`**

ì „ì²´ ê¸°ëŠ¥ êµ¬í˜„:

**ì…ë ¥ ì„¹ì…˜**:
- ì‹œë“œ í‚¤ì›Œë“œ ì…ë ¥
- ìµœì†Œ ë“±ê¸‰ ì„ íƒ (S/A/B/C/D)
- ë„¤ì´ë²„ ìë™ì™„ì„± ì‚¬ìš© ì—¬ë¶€
- ìºì‹œ ì‚¬ìš© ì—¬ë¶€

**ì§„í–‰ë¥  í‘œì‹œ**:
```python
def progress_callback(stage_name, current, total, overall_progress):
    st.progress(
        overall_progress / 100,
        text=f"[{current}/{total}] {stage_name}"
    )
```

**ê²°ê³¼ í‘œì‹œ**:
- ìš”ì•½ ë©”íŠ¸ë¦­ (4ê°œ ì¹´ë“œ)
- ë“±ê¸‰ ë¶„í¬ ì°¨íŠ¸
- ìµœê³  ê¸°íšŒ í‚¤ì›Œë“œ ìƒì„¸
- ìƒìœ„ 20ê°œ ê¸°íšŒ ëª©ë¡ (ë“±ê¸‰ë³„ ìƒ‰ìƒ)

**Excel ë‹¤ìš´ë¡œë“œ**:
```python
def create_excel_export(result) -> bytes:
    # Sheet 1: ìš”ì•½
    # Sheet 2: ê¸°íšŒ í‚¤ì›Œë“œ (ì „ì²´ ë°ì´í„°)
    # Sheet 3: ë“±ê¸‰ ë¶„í¬
```

**ìºì‹œ ê´€ë¦¬** (ì‚¬ì´ë“œë°”):
- ìºì‹œ í†µê³„ (ê°œìˆ˜, í¬ê¸°)
- ë§Œë£Œ ì‚­ì œ ë²„íŠ¼
- ì „ì²´ ì‚­ì œ ë²„íŠ¼

---

## ğŸ“Š í…ŒìŠ¤íŠ¸ í˜„í™©

### ì „ì²´ í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨: 100% âœ…

```
ì´ 80ê°œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ OpportunityScorer      : 16 tests âœ…
â”œâ”€â”€ CacheManager           : 17 tests âœ…
â”œâ”€â”€ SmartDiscoveryService  : 20 tests âœ…
â””â”€â”€ ProgressTracker        : 27 tests âœ…
```

### í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€

**Phase 1 í…ŒìŠ¤íŠ¸**:
- ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° ê²€ì¦: 8/8 âœ…

**Phase 2 í…ŒìŠ¤íŠ¸**:
- DataLab Analyzer v2.0 ê²€ì¦
- í‚¤ì›Œë“œ ìƒì„±ê¸° ê²€ì¦
- ë°°ì¹˜ í”„ë¡œì„¸ì„œ ê²€ì¦

**Phase 3 í…ŒìŠ¤íŠ¸**:
```bash
# ì „ì²´ ì‹¤í–‰
pytest tests/unit/ -v

# Phase 3ë§Œ ì‹¤í–‰
pytest tests/unit/test_opportunity_scorer.py \
       tests/unit/test_cache_manager.py \
       tests/unit/test_smart_discovery_service.py \
       tests/unit/test_progress_tracker.py -v
```

### ì£¼ìš” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

**OpportunityScorer**:
- ì ìˆ˜ ê³„ì‚° ì •í™•ì„±
- ë“±ê¸‰ íŒì • ë¡œì§
- ê°€ì¤‘ì¹˜ ê²€ì¦
- ë°°ì¹˜ ì²˜ë¦¬

**CacheManager**:
- ì €ì¥/ë¡œë“œ ê¸°ëŠ¥
- TTL ë§Œë£Œ ì²˜ë¦¬
- ì¸ë±ìŠ¤ ê´€ë¦¬
- íŒŒì¼ëª… ì•ˆì „í™”

**SmartDiscoveryService**:
- 5ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
- ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤
- ì§„í–‰ë¥  ì½œë°±
- ë“±ê¸‰ í•„í„°ë§

**ProgressTracker**:
- ë‹¨ì¼/ë‹¤ë‹¨ê³„ ì¶”ì 
- ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
- Streamlit í†µí•©
- ê°€ì¤‘ì¹˜ ê³„ì‚°

---

## ğŸ›  ê¸°ìˆ  ìŠ¤íƒ

### Backend
- **Python**: 3.14 (í˜¸í™˜ì„± í´ë°± ì²˜ë¦¬)
- **Pydantic**: ë°ì´í„° ê²€ì¦ ë° ì„¤ì • ê´€ë¦¬
- **httpx**: HTTP í´ë¼ì´ì–¸íŠ¸ (í´ë°±: ë”ë¯¸)
- **loguru**: ë¡œê¹… (í´ë°±: í‘œì¤€ logging)

### Frontend
- **Streamlit**: ì›¹ UI í”„ë ˆì„ì›Œí¬
- **Pandas**: ë°ì´í„° ì²˜ë¦¬ ë° Excel ìƒì„±
- **openpyxl**: Excel íŒŒì¼ ìƒì„±

### API
- **Naver DataLab API**: í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„
- **Naver Autocomplete API**: ìë™ì™„ì„± í‚¤ì›Œë“œ
- **Google Gemini API**: AI ì»¨í…ì¸  ìƒì„± (Phase 4)

### Testing
- **pytest**: ë‹¨ìœ„/í†µí•© í…ŒìŠ¤íŠ¸
- **pytest-cov**: í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€
- **pytest-mock**: ëª¨í‚¹

### ê°œë°œ ë„êµ¬
- **Git**: ë²„ì „ ê´€ë¦¬
- **GitHub**: ì›ê²© ì €ì¥ì†Œ

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

### Phase 4: AI Content Generation Engine (ì˜ˆì •)

**ëª©í‘œ**: Google Gemini ê¸°ë°˜ ë¸”ë¡œê·¸ ì»¨í…ì¸  ìë™ ìƒì„±

êµ¬í˜„ ì˜ˆì •:
1. **Step 4.1**: Gemini API í†µí•©
   - API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
   - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§

2. **Step 4.2**: ì»¨í…ì¸  ìƒì„± ì„œë¹„ìŠ¤
   - í…œí”Œë¦¿ ì‹œìŠ¤í…œ
   - ì„¹ì…˜ë³„ ìƒì„± (ì œëª©, ë„ì…, ë³¸ë¬¸, ê²°ë¡ )

3. **Step 4.3**: UI í˜ì´ì§€
   - í‚¤ì›Œë“œ ì„ íƒ
   - ìƒì„± ì˜µì…˜ ì„¤ì •
   - ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° ë° í¸ì§‘
   - Markdown/HTML ë‹¤ìš´ë¡œë“œ

### Phase 5: Performance & Dashboard (ì˜ˆì •)

**ëª©í‘œ**: ì„±ëŠ¥ ìµœì í™” ë° ëŒ€ì‹œë³´ë“œ

êµ¬í˜„ ì˜ˆì •:
1. **Performance Optimization**
   - Redis ìºì‹± (ì„ íƒì )
   - ë¹„ë™ê¸° ì²˜ë¦¬
   - ë°°ì¹˜ í¬ê¸° ìµœì í™”

2. **Dashboard**
   - ì „ì²´ í†µê³„ ëŒ€ì‹œë³´ë“œ
   - íŠ¸ë Œë“œ ì°¨íŠ¸
   - íˆìŠ¤í† ë¦¬ ê´€ë¦¬

---

## ğŸ“ ì‚¬ìš© ë°©ë²•

### í™˜ê²½ ì„¤ì •

1. **í™˜ê²½ ë³€ìˆ˜ ì„¤ì •** (`.env`)
```bash
NAVER_DATALAB_CLIENT_ID=your_client_id
NAVER_DATALAB_CLIENT_SECRET=your_client_secret
GOOGLE_GEMINI_API_KEY=your_api_key
```

2. **ì˜ì¡´ì„± ì„¤ì¹˜**
```bash
pip install -r requirements.txt
```

3. **í…ŒìŠ¤íŠ¸ ì‹¤í–‰**
```bash
pytest tests/unit/ -v
```

### Smart Discovery ì‚¬ìš©

**CLI ë°©ì‹** (ê°œë°œ/í…ŒìŠ¤íŠ¸):
```python
from backend.services.smart_discovery_service import SmartDiscoveryService

service = SmartDiscoveryService(use_cache=True)

result = service.discover(
    seed_keyword="ë¡±íŒ¨ë”©",
    use_autocomplete=True,
    min_grade='B'
)

print(f"ë°œê²¬ ê¸°íšŒ: {len(result.opportunities)}ê°œ")
print(f"ìµœê³  í‚¤ì›Œë“œ: {result.best_opportunity.keyword}")
print(f"ë“±ê¸‰: {result.best_opportunity.grade}")
```

**Streamlit UI ë°©ì‹**:
```bash
streamlit run app/pages/1_ğŸ”_smart_discovery.py
```

UI ì‚¬ìš©ë²•:
1. ì‹œë“œ í‚¤ì›Œë“œ ì…ë ¥ (ì˜ˆ: "ë¡±íŒ¨ë”©")
2. ìµœì†Œ ë“±ê¸‰ ì„ íƒ (S/A/B/C/D)
3. ì˜µì…˜ ì„¤ì • (ìë™ì™„ì„±, ìºì‹œ)
4. "ë¶„ì„ ì‹œì‘" ë²„íŠ¼ í´ë¦­
5. ê²°ê³¼ í™•ì¸ ë° Excel ë‹¤ìš´ë¡œë“œ

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Python 3.14 í˜¸í™˜ì„± ë¬¸ì œ

**ì¦ìƒ**: íŒ¨í‚¤ì§€ ë¹Œë“œ ì‹¤íŒ¨ (numpy, pandas, streamlit)

**í•´ê²°**:
```bash
# 1. ì‚¬ì „ ë¹Œë“œ wheel ì„¤ì¹˜
pip install numpy pandas --only-binary :all:

# 2. requirements.txt ë²„ì „ ì œì•½ ì™„í™”
numpy>=1.24.0  # íŠ¹ì • ë²„ì „ ê³ ì • X
```

### pydantic_settings ë¯¸ì„¤ì¹˜

**ì¦ìƒ**: `ModuleNotFoundError: No module named 'pydantic_settings'`

**í•´ê²°**: í´ë°± ì²˜ë¦¬ êµ¬í˜„ë¨
```python
# config/settings.py
try:
    from pydantic_settings import BaseSettings
except ImportError:
    class BaseSettings:
        def __init__(self, **data):
            # í´ë°± êµ¬í˜„
```

### Streamlit ë¯¸ì„¤ì¹˜

**ì¦ìƒ**: UI í˜ì´ì§€ ì‹¤í–‰ ë¶ˆê°€

**í•´ê²°**: ëª¨ë“  UI íŒŒì¼ì— í´ë°± ì²˜ë¦¬
```python
try:
    import streamlit as st
    HAS_STREAMLIT = True
except ImportError:
    HAS_STREAMLIT = False
    st = None
```

---

## ğŸ“Œ ì¤‘ìš” ë…¸íŠ¸

### ì˜ì¡´ì„± í´ë°± ì „ëµ
ëª¨ë“  ì„ íƒì  ì˜ì¡´ì„±ì— ëŒ€í•´ í´ë°± êµ¬í˜„:
- **loguru** â†’ í‘œì¤€ `logging`
- **httpx** â†’ ë”ë¯¸ êµ¬í˜„ (Phase 4 í•„ìˆ˜)
- **streamlit** â†’ None ì²˜ë¦¬
- **pydantic_settings** â†’ ê¸°ë³¸ í´ë˜ìŠ¤

### ë„¤ì´ë²„ API ì œí•œ
- **DataLab API**: ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ/ìš”ì²­
- **Rate Limit**: ë°°ì¹˜ ê°„ 1ì´ˆ ëŒ€ê¸° ê¶Œì¥
- **BatchProcessor**ê°€ ìë™ ì²˜ë¦¬

### ìºì‹œ ê´€ë¦¬
- ê¸°ë³¸ TTL: 24ì‹œê°„
- íŒŒì¼ ê¸°ë°˜: `.cache/` ë””ë ‰í† ë¦¬
- ìë™ ë§Œë£Œ ì‚­ì œ: ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ ì‹œ

---

## ğŸ“ˆ í”„ë¡œì íŠ¸ ë©”íŠ¸ë¦­

### ì½”ë“œ í†µê³„
- **ì´ Python íŒŒì¼**: 30+
- **ì´ ì½”ë“œ ë¼ì¸**: ~5,000 lines
- **í…ŒìŠ¤íŠ¸ íŒŒì¼**: 10+
- **í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**: 80+

### ì»¤ë°‹ íˆìŠ¤í† ë¦¬
- **Phase 1**: ì´ˆê¸° êµ¬ì¡° ìƒì„±
- **Phase 2**: í‚¤ì›Œë“œ ìƒì„± ì—”ì§„
- **Phase 3**: ìŠ¤ë§ˆíŠ¸ ë°œêµ´ ì„œë¹„ìŠ¤

### GitHub ì €ì¥ì†Œ
```
https://github.com/hyeonjeho3-star/blogerV2.git
```

---

## ğŸ¤ ê¸°ì—¬ì

- **Developer**: ì‚¬ìš©ì
- **AI Assistant**: Claude (Anthropic)
- **Tool**: Claude Code

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” ê°œì¸ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-19
**ë²„ì „**: Phase 3 ì™„ë£Œ
**ë‹¤ìŒ ë§ˆì¼ìŠ¤í†¤**: Phase 4 - AI Content Generation Engine
